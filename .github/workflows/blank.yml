name: Vimm Vault Scraper

on:
  workflow_dispatch:
    inputs:
      system:
        description: "Vault system (e.g., N64, Wii, GBA, GameCube, PS2)"
        required: true
        default: "N64"
      max_pages:
        description: "Max pages to scrape"
        required: true
        default: "50"

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          persist-credentials: false  # we will use a PAT for push
          
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 selenium webdriver-manager

      - name: Run scraper
        env:
          SYSTEM: ${{ github.event.inputs.system }}
          MAX_PAGES: ${{ github.event.inputs.max_pages }}
          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cat > scrape_and_build.py << 'PY'
          import os, json, re, time, subprocess
          import requests
          from bs4 import BeautifulSoup
          from selenium import webdriver
          from selenium.webdriver.chrome.service import Service
          from selenium.webdriver.chrome.options import Options
          from webdriver_manager.chrome import ChromeDriverManager

          SYSTEM = os.environ.get("SYSTEM", "N64")
          MAX_PAGES = int(os.environ.get("MAX_PAGES", "50"))

          base_url = "https://vimm.net/vault/"
          params_template = {"mode":"adv","p":"list","system":SYSTEM,"sort":"Title","sortOrder":"ASC"}

          # Selenium setup
          chrome_options = Options()
          chrome_options.add_argument("--headless")
          chrome_options.add_argument("--no-sandbox")
          chrome_options.add_argument("--disable-dev-shm-usage")
          service = Service(ChromeDriverManager().install())
          driver = webdriver.Chrome(service=service, options=chrome_options)

          all_games = []
          downloaded_ids = set()

          # Load previous index
          index_path = os.path.join("vimm","index.json")
          if os.path.exists(index_path):
              with open(index_path,"r",encoding="utf-8") as f:
                  all_games = json.load(f)
              downloaded_ids = {g["id"] for g in all_games if g.get("file")}

          session = requests.Session()
          session.headers.update({"User-Agent":"Metadata-Indexer","Accept-Language":"en-US,en;q=0.9"})

          for page in range(1, MAX_PAGES+1):
              params = dict(params_template)
              params["page"] = page
              url = f"{base_url}?mode={params['mode']}&p={params['p']}&system={params['system']}&sort={params['sort']}&sortOrder={params['sortOrder']}&page={page}"
              try:
                  driver.get(url)
                  soup = BeautifulSoup(driver.page_source,"html.parser")
              except Exception as e:
                  print(f"Failed to fetch page {page}: {e}")
                  break

              links = soup.select('a[href*="/vault/?id="]')
              if not links:
                  break

              for a in links:
                  title = a.get_text(strip=True)
                  href = a.get("href","")
                  url = f"https://vimm.net{href}" if href.startswith("/") else f"https://vimm.net/vault/{href}"
                  m = re.search(r"[?&]id=(\d+)", url)
                  game_id = m.group(1) if m else ""
                  if not title or game_id in downloaded_ids:
                      continue

                  safe_name = re.sub(r'[^A-Za-z0-9_. -]','_',title)[:100]
                  path = os.path.join("vimm","games",SYSTEM,safe_name)
                  os.makedirs(path,exist_ok=True)

                  download_url = None
                  game_file = None
                  try:
                      driver.get(url)
                      detail_soup = BeautifulSoup(driver.page_source,"html.parser")
                      dl = detail_soup.select_one('a[href*="/download.php"]')
                      if dl and dl.get("href"):
                          dl_href = dl.get("href")
                          download_url = f"https://vimm.net{dl_href}" if dl_href.startswith("/") else dl_href

                      if download_url:
                          with session.get(download_url, stream=True, timeout=60, verify=False) as resp:
                              if resp.status_code == 200:
                                  cd = resp.headers.get("Content-Disposition","")
                                  ext = ".bin"
                                  m = re.search(r'filename="?([^";]+)"?',cd)
                                  if m:
                                      filename = m.group(1)
                                      _, ext = os.path.splitext(filename)
                                  else:
                                      _, ext = os.path.splitext(download_url)

                                  game_file = os.path.join(path,f"{safe_name}{ext}")
                                  with open(game_file,"wb") as f:
                                      for chunk in resp.iter_content(chunk_size=8192):
                                          if chunk:
                                              f.write(chunk)
                                  print(f"Downloaded: {game_file}")
                  except Exception as e:
                      print(f"Failed to download {title}: {e}")

                  game_info = {"system":SYSTEM,"title":title,"id":game_id,"url":url,"folder":path,"download_url":download_url,"file":game_file}
                  all_games.append(game_info)
                  downloaded_ids.add(game_id)
                  time.sleep(2)

          # Save metadata
          os.makedirs("vimm",exist_ok=True)
          with open(index_path,"w",encoding="utf-8") as f:
              json.dump(all_games,f,indent=2,ensure_ascii=False)
          print(f"Updated metadata + files for {len(all_games)} games to {index_path}")

          # Git commit & push
          try:
              subprocess.run(["git","config","user.name","GitHub Actions"],check=True)
              subprocess.run(["git","config","user.email","actions@github.com"],check=True)
              subprocess.run(["git","add","vimm/"],check=True)
              subprocess.run(["git","commit","-m",f"Add/update {SYSTEM} games"],check=False)
              subprocess.run(["git","push","https://x-access-token:${REPO_TOKEN}@github.com/${GITHUB_REPOSITORY}.git","HEAD"],check=True)
              print("Pushed new games to repo")
          except Exception as e:
              print(f"Git push failed: {e}")

          driver.quit()
          PY

          python scrape_and_build.py
