name: Scrape and Download Vimm Games

on:
  workflow_dispatch:
    inputs:
      system:
        description: "Vault system (e.g., N64, NES, SNES)"
        required: true
        default: "N64"
      max_pages:
        description: "Maximum pages to scrape"
        required: true
        default: 50

jobs:
  scrape-download:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          persist-credentials: false  # We'll use token manually

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium webdriver-manager requests beautifulsoup4

      - name: Run scraper
        env:
          SYSTEM: ${{ github.event.inputs.system }}
          MAX_PAGES: ${{ github.event.inputs.max_pages }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cat > scrape_and_build.py << 'PY'
          import os, json, re, time, requests, subprocess
          from selenium import webdriver
          from selenium.webdriver.chrome.service import Service
          from selenium.webdriver.chrome.options import Options
          from webdriver_manager.chrome import ChromeDriverManager
          from bs4 import BeautifulSoup

          SYSTEM = os.environ.get("SYSTEM", "N64")
          MAX_PAGES = int(os.environ.get("MAX_PAGES", "50"))

          base_url = "https://vimm.net/vault/"
          session = requests.Session()
          session.headers.update({
              "User-Agent": "Metadata-Indexer (GitHub Actions)",
              "Accept-Language": "en-US,en;q=0.9",
          })

          # Initialize Selenium Chrome
          chrome_options = Options()
          chrome_options.add_argument("--headless")
          chrome_options.add_argument("--no-sandbox")
          chrome_options.add_argument("--disable-dev-shm-usage")
          service = Service(ChromeDriverManager().install())
          driver = webdriver.Chrome(service=service, options=chrome_options)

          # Load previous index
          index_path = os.path.join("vimm", "index.json")
          if os.path.exists(index_path):
              with open(index_path, "r", encoding="utf-8") as f:
                  all_games = json.load(f)
              downloaded_ids = {g["id"] for g in all_games if g.get("file")}
          else:
              all_games = []
              downloaded_ids = set()

          for page in range(1, MAX_PAGES + 1):
              params = {
                  "mode": "adv",
                  "p": "list",
                  "system": SYSTEM,
                  "sort": "Title",
                  "sortOrder": "ASC",
                  "page": page
              }
              try:
                  driver.get(f"{base_url}?mode=adv&p=list&system={SYSTEM}&sort=Title&sortOrder=ASC&page={page}")
                  html = driver.page_source
              except Exception as e:
                  print(f"Failed to fetch page {page}: {e}")
                  break

              soup = BeautifulSoup(html, "html.parser")
              links = soup.select('a[href*="/vault/?id="]')
              if not links:
                  break

              for a in links:
                  title = a.get_text(strip=True)
                  href = a.get("href", "")
                  url = f"https://vimm.net{href}" if href.startswith("/") else f"https://vimm.net/vault/{href}"
                  m = re.search(r"[?&]id=(\d+)", url)
                  game_id = m.group(1) if m else ""
                  if not title or game_id in downloaded_ids:
                      continue

                  safe_name = re.sub(r'[^A-Za-z0-9_. -]', '_', title)[:100]
                  path = os.path.join("vimm", "games", SYSTEM, safe_name)
                  os.makedirs(path, exist_ok=True)

                  download_url = None
                  game_file = None
                  try:
                      driver.get(url)
                      detail_html = driver.page_source
                      detail_soup = BeautifulSoup(detail_html, "html.parser")
                      dl = detail_soup.select_one('a[href*="/download.php"]')
                      if dl and dl.get("href"):
                          dl_href = dl.get("href")
                          download_url = f"https://vimm.net{dl_href}" if dl_href.startswith("/") else dl_href

                      if download_url:
                          with session.get(download_url, stream=True, timeout=60) as resp:
                              if resp.status_code == 200:
                                  cd = resp.headers.get("Content-Disposition", "")
                                  ext = ".bin"
                                  m = re.search(r'filename="?([^";]+)"?', cd)
                                  if m:
                                      filename = m.group(1)
                                      _, ext = os.path.splitext(filename)
                                  else:
                                      _, ext = os.path.splitext(download_url)

                                  game_file = os.path.join(path, f"{safe_name}{ext}")
                                  with open(game_file, "wb") as f:
                                      for chunk in resp.iter_content(chunk_size=8192):
                                          if chunk:
                                              f.write(chunk)
                                  print(f"Downloaded: {game_file}")
                  except Exception as e:
                      print(f"Failed to download {title}: {e}")

                  game_info = {
                      "system": SYSTEM,
                      "title": title,
                      "id": game_id,
                      "url": url,
                      "folder": path,
                      "download_url": download_url,
                      "file": game_file,
                  }
                  all_games.append(game_info)
                  downloaded_ids.add(game_id)
                  time.sleep(2)

          driver.quit()

          # Save metadata
          os.makedirs("vimm", exist_ok=True)
          with open(index_path, "w", encoding="utf-8") as f:
              json.dump(all_games, f, indent=2, ensure_ascii=False)
          print(f"Updated metadata + files for {len(all_games)} games to {index_path}")

          # Git commit & push
          try:
              subprocess.run(["git", "config", "user.name", "github-actions"], check=True)
              subprocess.run(["git", "config", "user.email", "github-actions@users.noreply.github.com"], check=True)
              subprocess.run(["git", "add", "vimm/"], check=True)
              subprocess.run(["git", "commit", "-m", f"Add/update {SYSTEM} games"], check=False)
              # Use token for push
              token = os.environ.get("GITHUB_TOKEN")
              remote_url = f"https://x-access-token:{token}@github.com/{os.environ['GITHUB_REPOSITORY']}.git"
              subprocess.run(["git", "push", remote_url, "HEAD"], check=True)
              print("Pushed new games to repo")
          except Exception as e:
              print(f"Git push failed: {e}")
          PY

          python scrape_and_build.py
